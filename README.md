<p align="center">
  <img src="https://img.shields.io/badge/PROJECT-ANCHOR-0d1117?style=for-the-badge&labelColor=0d1117&color=58a6ff&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJ3aGl0ZSI+PGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMTAiIGZpbGw9Im5vbmUiIHN0cm9rZT0id2hpdGUiIHN0cm9rZS13aWR0aD0iMiIvPjxsaW5lIHgxPSIxMiIgeTE9IjIiIHgyPSIxMiIgeTI9IjIyIiBzdHJva2U9IndoaXRlIiBzdHJva2Utd2lkdGg9IjIiLz48bGluZSB4MT0iMiIgeTE9IjEyIiB4Mj0iMjIiIHkyPSIxMiIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIi8+PC9zdmc+" alt="Project Anchor"/>
</p>

<h1 align="center">
  <code>GRAVITY-</code>
</h1>

<p align="center">
  <strong>Forensic Research Aggregation & Epistemic Intelligence System</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11+-3776AB?style=flat-square&logo=python&logoColor=white" alt="Python 3.11+"/>
  <img src="https://img.shields.io/badge/Tests-390_Passing-2ea043?style=flat-square&logo=pytest&logoColor=white" alt="Tests"/>
  <img src="https://img.shields.io/badge/CLI_Commands-87-58a6ff?style=flat-square&logo=windowsterminal&logoColor=white" alt="CLI"/>
  <img src="https://img.shields.io/badge/Database-39_Tables-f0883e?style=flat-square&logo=sqlite&logoColor=white" alt="DB"/>
  <img src="https://img.shields.io/badge/Phases-7_Complete-a371f7?style=flat-square&logo=stackblitz&logoColor=white" alt="Phases"/>
  <img src="https://img.shields.io/badge/Rust-Smart_Contracts-dea584?style=flat-square&logo=rust&logoColor=white" alt="Rust"/>
  <img src="https://img.shields.io/badge/IPFS-Integrated-65c2cb?style=flat-square&logo=ipfs&logoColor=white" alt="IPFS"/>
  <img src="https://img.shields.io/badge/Crypto-Ed25519-d63384?style=flat-square&logo=letsencrypt&logoColor=white" alt="Crypto"/>
  <img src="https://img.shields.io/badge/License-Proprietary-888?style=flat-square" alt="License"/>
</p>

<p align="center">
  <em>A seven-phase forensic research operating system that collects, correlates, scores, and tracks<br/>publicly available information with cryptographic integrity and blockchain anchoring guarantees.</em>
</p>

<p align="center">
  <sub>The system does not confirm or deny claims. It gathers, organizes, correlates, scores, and tracks data.</sub>
</p>

---

## Case File

> **Project Anchor â€” August 12 Gravity Event â€” Thomas Webb**

---

## Table of Contents

> Color key: ðŸŸ¦ Architecture &nbsp; ðŸŸ© Phases &nbsp; ðŸŸ§ CLI &nbsp; ðŸŸª Data &nbsp; ðŸŸ¥ Technical &nbsp; â¬œ Operations

| # | Section | Category | Description |
|:-:|---------|:--------:|-------------|
| 1 | [System Architecture](#-system-architecture) | ðŸŸ¦ | High-level design, data flow, phase pipeline |
| 2 | [Phase Pipeline Overview](#-phase-pipeline-overview) | ðŸŸ¦ | Phase dependency graph and capability matrix |
| 3 | [Repository Structure](#-repository-structure) | ðŸŸ¦ | Complete file tree (36 modules, 6 test suites) |
| 4 | [Phase I â€” Research & Collection](#-phase-i--research--collection) | ðŸŸ© | Data scraping, PDF analysis, physics, NLP, IPFS |
| 5 | [Phase II â€” Cryptographic Integrity](#-phase-ii--cryptographic-integrity) | ðŸŸ© | Ed25519, Merkle trees, FOIA, audit reports |
| 6 | [Phase III â€” Mathematical Framework](#-phase-iii--mathematical-framework) | ðŸŸ© | Equation parsing, dimensional analysis, claim graph |
| 7 | [Phase IV â€” Quantitative Scoring](#-phase-iv--quantitative-scoring) | ðŸŸ© | Bayesian confidence, entropy, citation density |
| 8 | [Phase V â€” Temporal Dynamics](#-phase-v--temporal-dynamics) | ðŸŸ© | Timelines, drift kinematics, stability, alerts |
| 9 | [Phase VI â€” Source Intelligence](#-phase-vi--source-intelligence--network-forensics) | ðŸŸ© | Reputation, influence, coordination, provenance |
| 10 | [Phase VII â€” Scientific Optimization](#-phase-vii--scientific-optimization--blockchain-anchoring) | ðŸŸ© | Math analysis, Rust contracts, blockchain anchoring |
| 11 | [CLI Command Reference](#-cli-command-reference) | ðŸŸ§ | All 87 commands organized by phase |
| 12 | [Database Schema](#-database-schema) | ðŸŸª | 39 tables across 7 phases |
| 12 | [Scoring & Algorithm Reference](#-scoring--algorithm-reference) | ðŸŸ¥ | Mathematical formulas, weights, thresholds |
| 13 | [Flow Diagrams](#-flow-diagrams) | ðŸŸ¥ | Data pipeline, scoring cascade, alert flow |
| 15 | [Testing](#-testing) | â¬œ | 390 tests, per-phase breakdown |
| 15 | [IPFS Integration](#-ipfs-integration) | â¬œ | Proof chain, pinning, IPNS workflow |
| 16 | [Operational Scope & Reproducibility](#-operational-scope--reproducibility) | â¬œ | Legal boundaries, audit trail, portability |
| 17 | [Quick Start](#-quick-start) | â¬œ | Installation and first run |
| 18 | [Dependencies](#-dependencies) | â¬œ | Required packages and versions |

---

## ðŸŸ¦ System Architecture

```mermaid
graph TB
    subgraph INPUT["ðŸ“¥ DATA SOURCES"]
        direction LR
        R[Reddit / Social]
        W[Wayback Machine]
        G[Gov Records]
        A[Academic DBs]
        P[PDF Documents]
        F[FOIA Documents]
    end

    subgraph PHASE1["ðŸŸ¢ PHASE I â€” Collection"]
        direction LR
        SC[Scrapers]
        PA[PDF Analyzer]
        PE[Physics Engine]
        NLP[NLP Analyzer]
    end

    subgraph PHASE2["ðŸ”µ PHASE II â€” Integrity"]
        direction LR
        CR[Ed25519 Crypto]
        MK[Merkle Trees]
        FO[FOIA Forensics]
        AU[Audit Reports]
    end

    subgraph PHASE3["ðŸŸ¡ PHASE III â€” Math"]
        direction LR
        EQ[Equation Parser]
        DA[Dim. Analysis]
        CG[Claim Graph]
        SY[SymPy CAS]
    end

    subgraph PHASE4["ðŸŸ  PHASE IV â€” Scoring"]
        direction LR
        BC[Bayesian Scorer]
        ME[Mutation Entropy]
        CD[Citation Density]
        CA[Contradictions]
    end

    subgraph PHASE5["ðŸ”´ PHASE V â€” Temporal"]
        direction LR
        CT[Conf. Timeline]
        ET[Entropy Trend]
        DK[Drift Kinem.]
        AL[Alert Engine]
    end

    subgraph PHASE6["ðŸŸ£ PHASE VI â€” Intelligence"]
        direction LR
        SR[Source Reputation]
        IN[Influence Network]
        CO[Coordination Det.]
        DP[Deep Provenance]
    end

    subgraph PHASE7["âšª PHASE VII â€” Scientific Optimization"]
        direction LR
        MF[Missing Factors]
        SA[Stability Analysis]
        FP[Formal Proofs]
        BA[Blockchain Anchors]
    end

    subgraph STORAGE["ðŸ’¾ STORAGE LAYER"]
        DB[(SQLite<br/>39 Tables)]
        IPFS[(IPFS<br/>Proof Chain)]
        LOG[Logs]
        CHAIN[(Blockchain<br/>Anchors)]
    end

    subgraph OUTPUT["ðŸ“¤ OUTPUT"]
        RPT[Reports]
        CLI[CLI / 87 Commands]
        DASH[Dashboard]
    end

    INPUT --> PHASE1
    PHASE1 --> PHASE2
    PHASE2 --> PHASE3
    PHASE3 --> PHASE4
    PHASE4 --> PHASE5
    PHASE5 --> PHASE6
    PHASE6 --> PHASE7

    PHASE1 --> STORAGE
    PHASE2 --> STORAGE
    PHASE3 --> STORAGE
    PHASE4 --> STORAGE
    PHASE5 --> STORAGE
    PHASE6 --> STORAGE
    PHASE7 --> STORAGE

    STORAGE --> OUTPUT

    style INPUT fill:#1a1a2e,stroke:#58a6ff,color:#c9d1d9
    style PHASE1 fill:#0d2818,stroke:#2ea043,color:#c9d1d9
    style PHASE2 fill:#0d1b2e,stroke:#58a6ff,color:#c9d1d9
    style PHASE3 fill:#2e2a0d,stroke:#d29922,color:#c9d1d9
    style PHASE4 fill:#2e1a0d,stroke:#f0883e,color:#c9d1d9
    style PHASE5 fill:#2e0d0d,stroke:#f85149,color:#c9d1d9
    style PHASE6 fill:#1f0d2e,stroke:#a371f7,color:#c9d1d9
    style PHASE7 fill:#1a1a1a,stroke:#8b949e,color:#c9d1d9
    style STORAGE fill:#161b22,stroke:#8b949e,color:#c9d1d9
    style OUTPUT fill:#0d1117,stroke:#58a6ff,color:#c9d1d9
```

---

## ðŸŸ¦ Phase Pipeline Overview

### Capability Matrix

```mermaid
%%{init: {'theme': 'dark', 'themeVariables': {'fontSize': '14px'}}}%%
graph LR
    subgraph LEGEND["PHASE LEGEND"]
        direction TB
        L1["ðŸŸ¢ I: Collection â€” 8 modules â€” 9 tests"]
        L2["ðŸ”µ II: Integrity â€” 6 modules â€” 24 tests"]
        L3["ðŸŸ¡ III: Math â€” 5 modules â€” 34 tests"]
        L4["ðŸŸ  IV: Scoring â€” 6 modules â€” 42 tests"]
        L5["ðŸ”´ V: Temporal â€” 6 modules â€” 75 tests"]
        L6["ðŸŸ£ VI: Intelligence â€” 5 modules â€” 100 tests"]
    end

    L1 --> L2 --> L3 --> L4 --> L5 --> L6

    style L1 fill:#0d2818,stroke:#2ea043,color:#7ee787
    style L2 fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff
    style L3 fill:#2e2a0d,stroke:#d29922,color:#e3b341
    style L4 fill:#2e1a0d,stroke:#f0883e,color:#ffa657
    style L5 fill:#2e0d0d,stroke:#f85149,color:#ff7b72
    style L6 fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style LEGEND fill:#0d1117,stroke:#30363d,color:#c9d1d9
```

### Phase Statistics

| Phase | Color | Name | Modules | Tests | Tables | CLI Commands |
|:-----:|:-----:|------|:-------:|:-----:|:------:|:------------:|
| **I** | ðŸŸ¢ | Research & Collection | 8 | 9 | 9 | 21 |
| **II** | ðŸ”µ | Cryptographic Integrity | 6 | 24 | 7 | 12 |
| **III** | ðŸŸ¡ | Mathematical Framework | 5 | 34 | 6 | 11 |
| **IV** | ðŸŸ  | Quantitative Scoring | 6 | 42 | 3 | 8 |
| **V** | ðŸ”´ | Temporal Dynamics | 6 | 75 | 4 | 11 |
| **VI** | ðŸŸ£ | Source Intelligence | 5 | 100 | 4 | 11 |
| | | **TOTALS** | **36** | **284** | **33** | **77** |

### Phase Dependency Flow

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    I["ðŸŸ¢ Phase I\nCollection\n8 modules"]
    II["ðŸ”µ Phase II\nIntegrity\n6 modules"]
    III["ðŸŸ¡ Phase III\nMath\n5 modules"]
    IV["ðŸŸ  Phase IV\nScoring\n6 modules"]
    V["ðŸ”´ Phase V\nTemporal\n6 modules"]
    VI["ðŸŸ£ Phase VI\nIntelligence\n5 modules"]

    I -->|"raw data"| II
    II -->|"verified data"| III
    III -->|"structured claims"| IV
    IV -->|"scored claims"| V
    V -->|"temporal profiles"| VI

    I -.->|"direct feed"| III
    I -.->|"direct feed"| IV
    III -.->|"graph data"| VI

    style I fill:#0d2818,stroke:#2ea043,color:#7ee787,stroke-width:2px
    style II fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff,stroke-width:2px
    style III fill:#2e2a0d,stroke:#d29922,color:#e3b341,stroke-width:2px
    style IV fill:#2e1a0d,stroke:#f0883e,color:#ffa657,stroke-width:2px
    style V fill:#2e0d0d,stroke:#f85149,color:#ff7b72,stroke-width:2px
    style VI fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff,stroke-width:2px
```

---

## ðŸŸ¦ Repository Structure

```
project-anchor-research/
â”œâ”€â”€ main.py                              # CLI orchestrator (77 commands)
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                                # SQLite DB, keys, downloaded files
â”‚   â””â”€â”€ keys/                            # Ed25519 signing keypairs
â”œâ”€â”€ logs/                                # Timestamped operation logs
â”œâ”€â”€ reports/                             # Generated reports
â”‚   â””â”€â”€ audits/                          # Audit reports (JSON, HTML, Markdown)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                        # Configuration & constants
â”‚   â”œâ”€â”€ database.py                      # SQLite schema (33 tables) & helpers
â”‚   â”œâ”€â”€ logger.py                        # Structured logging
â”‚   â”‚
â”‚   â”œâ”€â”€ collectors/                      # ðŸŸ¢ Phase I â€” Data collection
â”‚   â”‚   â”œâ”€â”€ base_scraper.py              #   Abstract base with rate limiting
â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py            #   Reddit JSON endpoint scraper
â”‚   â”‚   â”œâ”€â”€ wayback_scraper.py           #   Internet Archive CDX API
â”‚   â”‚   â””â”€â”€ web_search_scraper.py        #   DuckDuckGo HTML scraper
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzers/                       # ðŸŸ¢ Phase I â€” Document analysis
â”‚   â”‚   â””â”€â”€ pdf_analyzer.py              #   PDF metadata, fonts, markings
â”‚   â”‚
â”‚   â”œâ”€â”€ crossref/                        # ðŸŸ¢ Phase I â€” External databases
â”‚   â”‚   â”œâ”€â”€ academic_records.py          #   CrossRef, Semantic Scholar, OpenAlex
â”‚   â”‚   â”œâ”€â”€ government_records.py        #   NASA NTRS, FOIA.gov, FPDS
â”‚   â”‚   â””â”€â”€ research_sources.py          #   Extended source search
â”‚   â”‚
â”‚   â”œâ”€â”€ physics/                         # ðŸŸ¢ Phase I â€” Physics verification
â”‚   â”‚   â”œâ”€â”€ gravity_engine.py            #   Gravitational physics computations
â”‚   â”‚   â””â”€â”€ wave_engine.py               #   Wave science computations
â”‚   â”‚
â”‚   â”œâ”€â”€ nlp/                             # ðŸŸ¢ Phase I â€” Narrative analysis
â”‚   â”‚   â””â”€â”€ narrative_analyzer.py        #   Pattern detection & similarity
â”‚   â”‚
â”‚   â”œâ”€â”€ ipfs/                            # ðŸŸ¢ Phase I â€” Immutable storage
â”‚   â”‚   â”œâ”€â”€ ipfs_client.py               #   Kubo RPC API client
â”‚   â”‚   â”œâ”€â”€ proof_chain.py               #   DAG-linked evidence chain
â”‚   â”‚   â”œâ”€â”€ evidence_archiver.py         #   Orchestrates pinning to IPFS
â”‚   â”‚   â”œâ”€â”€ ipns_publisher.py            #   IPNS name publishing
â”‚   â”‚   â””â”€â”€ multi_gateway.py             #   Multi-gateway health & pinning
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/                       # ðŸŸ¢ Phase I â€” Visualization
â”‚   â”‚   â””â”€â”€ dashboard.py                 #   Plotly/Dash interactive dashboard
â”‚   â”‚
â”‚   â”œâ”€â”€ crypto/                          # ðŸ”µ Phase II â€” Cryptographic integrity
â”‚   â”‚   â””â”€â”€ signature_manager.py         #   Ed25519 keypair & CID signing
â”‚   â”‚
â”‚   â”œâ”€â”€ proofs/                          # ðŸ”µ Phase II â€” Merkle verification
â”‚   â”‚   â””â”€â”€ merkle_snapshot.py           #   Merkle tree snapshots of DB state
â”‚   â”‚
â”‚   â”œâ”€â”€ foia/                            # ðŸ”µ Phase II â€” FOIA forensics
â”‚   â”‚   â”œâ”€â”€ foia_ingester.py             #   FOIA document ingestion
â”‚   â”‚   â””â”€â”€ document_forensics.py        #   Document authenticity scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ investigations/                  # ðŸ”µ Phase II â€” Case databases
â”‚   â”‚   â”œâ”€â”€ scientist_cases.py           #   Historical scientist cases DB
â”‚   â”‚   â””â”€â”€ tesla_module.py              #   Tesla investigation module
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/                         # ðŸ”µ Phase II â€” Audit reports
â”‚   â”‚   â””â”€â”€ audit_generator.py           #   Comprehensive audit report gen
â”‚   â”‚
â”‚   â”œâ”€â”€ taxonomy/                        # ðŸ”µ Phase II â€” Knowledge base
â”‚   â”‚   â””â”€â”€ knowledge_base.py            #   Taxonomy classification system
â”‚   â”‚
â”‚   â”œâ”€â”€ math/                            # ðŸŸ¡ Phase III â€” Mathematical framework
â”‚   â”‚   â”œâ”€â”€ equation_parser.py           #   Plaintext & LaTeX â†’ SymPy AST
â”‚   â”‚   â”œâ”€â”€ dimensional_analyzer.py      #   Dimensional consistency checking
â”‚   â”‚   â”œâ”€â”€ symbolic_refactor.py         #   CAS: simplify, factor, diff
â”‚   â”‚   â”œâ”€â”€ derivation_logger.py         #   Step-by-step derivation chains
â”‚   â”‚   â””â”€â”€ equation_audit_report.py     #   Math forensics audit reports
â”‚   â”‚
â”‚   â””â”€â”€ graph/                           # ðŸŸ¡ðŸŸ ðŸ”´ðŸŸ£ Phases IIIâ€“VI
â”‚       â”œâ”€â”€ claim_graph.py               #   ðŸŸ¡ III: Typed claim/source/entity graph
â”‚       â”œâ”€â”€ propagation_graph.py         #   ðŸŸ¡ III: NetworkX propagation mapping
â”‚       â”œâ”€â”€ confidence_scorer.py         #   ðŸŸ  IV: Bayesian 6-component scoring
â”‚       â”œâ”€â”€ mutation_entropy.py          #   ðŸŸ  IV: Shannon entropy of mutations
â”‚       â”œâ”€â”€ citation_density.py          #   ðŸŸ  IV: Cross-reference density scoring
â”‚       â”œâ”€â”€ contradiction_analyzer.py    #   ðŸŸ  IV: Tension mapping & conflict clusters
â”‚       â”œâ”€â”€ propagation_tracker.py       #   ðŸŸ  IV: Event velocity & amplification
â”‚       â”œâ”€â”€ claim_scoring_report.py      #   ðŸŸ  IV: Aggregate epistemic reports
â”‚       â”œâ”€â”€ confidence_timeline.py       #   ðŸ”´ V: Temporal confidence tracking
â”‚       â”œâ”€â”€ entropy_trend.py             #   ðŸ”´ V: H(t) series, dH/dt, dÂ²H/dtÂ²
â”‚       â”œâ”€â”€ drift_kinematics.py          #   ðŸ”´ V: Velocity, acceleration, jerk
â”‚       â”œâ”€â”€ stability_classifier.py      #   ðŸ”´ V: 5-state epistemic classifier
â”‚       â”œâ”€â”€ alert_engine.py              #   ðŸ”´ V: Rule-based anomaly detection
â”‚       â”œâ”€â”€ lifecycle_report.py          #   ðŸ”´ V: 10-section lifecycle reports
â”‚       â”œâ”€â”€ source_reputation.py         #   ðŸŸ£ VI: EMA credibility tracking
â”‚       â”œâ”€â”€ influence_network.py         #   ðŸŸ£ VI: Source amplification graphs
â”‚       â”œâ”€â”€ coordination_detector.py     #   ðŸŸ£ VI: Temporal clustering detection
â”‚       â”œâ”€â”€ provenance_deep.py           #   ðŸŸ£ VI: Multi-layer origin tracing
â”‚       â””â”€â”€ source_forensics_report.py   #   ðŸŸ£ VI: Comprehensive intelligence reports
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_physics.py                  # ðŸŸ¢   9 tests â€” Physics engine
    â”œâ”€â”€ test_phase2.py                   # ðŸ”µ  24 tests â€” Crypto & integrity
    â”œâ”€â”€ test_phase3.py                   # ðŸŸ¡  34 tests â€” Math & claim graph
    â”œâ”€â”€ test_phase4.py                   # ðŸŸ   42 tests â€” Scoring engine
    â”œâ”€â”€ test_phase5.py                   # ðŸ”´  75 tests â€” Temporal dynamics
    â””â”€â”€ test_phase6.py                   # ðŸŸ£ 100 tests â€” Source intelligence
```

---

## ðŸŸ© Phase I â€” Research & Collection

> ðŸŸ¢ **Core data gathering and analysis layer**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph SOURCES["External Sources"]
        S1["ðŸŒ Reddit"]
        S2["ðŸ“š Wayback"]
        S3["ðŸ›ï¸ Gov DBs"]
        S4["ðŸŽ“ Academic"]
        S5["ðŸ“„ PDFs"]
    end

    subgraph ENGINES["Processing Engines"]
        E1["Scraper Engine"]
        E2["PDF Analyzer"]
        E3["Physics Engine"]
        E4["NLP Engine"]
    end

    subgraph OUT["Outputs"]
        O1["ðŸ“Š Reports"]
        O2["ðŸ“Œ IPFS Archive"]
        O3["ðŸ’¾ Database"]
    end

    S1 & S2 --> E1
    S3 & S4 --> E1
    S5 --> E2
    E1 --> E3
    E1 --> E4
    E2 --> O3
    E3 --> O1
    E4 --> O3
    E1 --> O2

    style SOURCES fill:#0d2818,stroke:#2ea043,color:#7ee787
    style ENGINES fill:#0d2818,stroke:#2ea043,color:#7ee787
    style OUT fill:#161b22,stroke:#8b949e,color:#c9d1d9
```

| # | Module | Description |
|:-:|--------|-------------|
| 1 | **Data Collection** | Scrapes Reddit, Wayback Machine, web search for earliest references |
| 2 | **Document Analysis** | PDF metadata extraction, font analysis, classification marking detection |
| 3 | **Origin Trace** | Identifies earliest indexed references, maps repost sequences |
| 4 | **Government Cross-Ref** | Searches NASA NTRS, FOIA.gov, FPDS, USASpending |
| 5 | **Academic Verification** | Searches CrossRef, Semantic Scholar, OpenAlex |
| 6 | **Physics Consistency** | GW strain, binding energy, tidal forces, merger energetics |
| 7 | **Narrative Analysis** | Detects whistleblower/disappearance/urgency patterns via NLP |
| 8 | **IPFS Evidence Archive** | Immutable, content-addressed proof chain on IPFS |

---

## ðŸŸ© Phase II â€” Cryptographic Integrity

> ðŸ”µ **Tamper-proof evidence anchoring and expanded research capabilities**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph CRYPTO["Cryptographic Layer"]
        K["ðŸ”‘ Ed25519\nKeypair Gen"]
        S["âœï¸ CID Signing"]
        V["âœ… Verification"]
    end

    subgraph MERKLE["Merkle Layer"]
        M["ðŸŒ³ DB Snapshot"]
        MV["ðŸ” Integrity\nVerification"]
    end

    subgraph RESEARCH["Extended Research"]
        FO["ðŸ“‹ FOIA Forensics"]
        SC["ðŸ”¬ Scientist Cases"]
        AU["ðŸ“Š Audit Reports"]
    end

    K --> S --> V
    M --> MV
    FO --> AU
    SC --> AU

    style CRYPTO fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff
    style MERKLE fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff
    style RESEARCH fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff
```

| # | Module | Description |
|:-:|--------|-------------|
| 9 | **Ed25519 Signatures** | Generate keypairs, sign CIDs, verify signatures |
| 10 | **Merkle Snapshots** | Hash entire DB state into Merkle tree, verify integrity |
| 11 | **FOIA Forensics** | Document authenticity scoring and classification detection |
| 12 | **Scientist Cases DB** | Historical cases of suppressed/disputed scientists |
| 13 | **Audit Reports** | Comprehensive HTML/JSON/Markdown audit generation |
| 14 | **Taxonomy Knowledge Base** | Classification system for organizing research categories |

---

## ðŸŸ© Phase III â€” Mathematical Framework

> ðŸŸ¡ **Symbolic computation and structured evidence graph**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    subgraph PARSE["Equation Processing"]
        P1["ðŸ“ Plaintext\nInput"]
        P2["ðŸ“ LaTeX\nInput"]
        P3["ðŸ”§ SymPy AST\nConversion"]
    end

    subgraph ANALYSIS["Mathematical Analysis"]
        A1["ðŸ“ Dimensional\nChecking"]
        A2["ðŸ§® Symbolic\nRefactoring"]
        A3["ðŸ“– Derivation\nLogging"]
    end

    subgraph GRAPH["Evidence Graph"]
        G1["ðŸ”— Claim Nodes"]
        G2["ðŸ“š Source Nodes"]
        G3["ðŸ‘¤ Entity Nodes"]
        G4["âš¡ Weighted Edges"]
    end

    P1 & P2 --> P3
    P3 --> A1 & A2 & A3
    A1 & A2 & A3 --> GRAPH

    style PARSE fill:#2e2a0d,stroke:#d29922,color:#e3b341
    style ANALYSIS fill:#2e2a0d,stroke:#d29922,color:#e3b341
    style GRAPH fill:#2e2a0d,stroke:#d29922,color:#e3b341
```

| # | Module | Description |
|:-:|--------|-------------|
| 15 | **Equation Parser** | Plaintext & LaTeX â†’ SymPy AST with SHA-256 fingerprints |
| 16 | **Dimensional Analyzer** | Verify dimensional consistency of physics equations |
| 17 | **Symbolic Refactor** | CAS operations: simplify, factor, expand, differentiate, series |
| 18 | **Derivation Logger** | Step-by-step mathematical derivation chains with persistence |
| 19 | **Claim Graph** | Typed nodes (claims, sources, entities) with weighted edges |

---

## ðŸŸ© Phase IV â€” Quantitative Scoring

> ðŸŸ  **Bayesian scoring engine and quantitative analysis**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph INPUTS["Score Inputs"]
        I1["Prior Probability"]
        I2["Source Credibility"]
        I3["Citation Density"]
        I4["Contradiction Map"]
        I5["Verification Status"]
        I6["Mutation Decay"]
    end

    subgraph ENGINE["Bayesian Engine"]
        BE["âš–ï¸ Weighted\nComposite\nScorer"]
    end

    subgraph OUTPUTS["Score Outputs"]
        O1["ðŸ“Š Confidence\nScore 0â€“1"]
        O2["ðŸ“‹ Ranking\nReport"]
        O3["âš ï¸ Flags &\nAnomalies"]
    end

    I1 & I2 & I3 --> BE
    I4 & I5 & I6 --> BE
    BE --> O1 & O2 & O3

    style INPUTS fill:#2e1a0d,stroke:#f0883e,color:#ffa657
    style ENGINE fill:#2e1a0d,stroke:#f0883e,color:#ffa657
    style OUTPUTS fill:#2e1a0d,stroke:#f0883e,color:#ffa657
```

| # | Module | Description |
|:-:|--------|-------------|
| 20 | **Confidence Scorer** | 6-component Bayesian scoring: prior, credibility, citation, contradiction, verification, mutation decay |
| 21 | **Mutation Entropy** | Shannon entropy of claim text mutations, drift velocity, semantic stability |
| 22 | **Citation Density** | Cross-reference density scoring with quality weighting |
| 23 | **Contradiction Analyzer** | Tension mapping, conflict cluster detection (union-find), contested claim identification |
| 24 | **Propagation Tracker** | Event logging, propagation velocity, cascade depth, amplification factor |
| 25 | **Scoring Reports** | Aggregate epistemic reports with integrity scores and rankings |

---

## ðŸŸ© Phase V â€” Temporal Dynamics

> ðŸ”´ **Temporal tracking, kinematic analysis, stability classification, and alerting**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    subgraph SIGNALS["Temporal Signals"]
        S1["dC/dt\nConfidence Rate"]
        S2["dH/dt\nEntropy Velocity"]
        S3["dÂ²H/dtÂ²\nEntropy Accel."]
        S4["dÂ³d/dtÂ³\nDrift Jerk"]
    end

    subgraph CLASSIFIER["State Machine"]
        C1["ðŸŸ¢ Stable"]
        C2["ðŸ”µ Converging"]
        C3["ðŸŸ¡ Volatile"]
        C4["ðŸŸ  Diverging"]
        C5["ðŸ”´ Critical"]
    end

    subgraph ALERTS["Alert Engine"]
        A1["â„¹ï¸ Info"]
        A2["âš ï¸ Warning"]
        A3["ðŸš¨ Critical"]
    end

    S1 & S2 & S3 & S4 --> CLASSIFIER
    CLASSIFIER --> ALERTS
    C1 -.-> C2 -.-> C3 -.-> C4 -.-> C5

    style SIGNALS fill:#2e0d0d,stroke:#f85149,color:#ff7b72
    style CLASSIFIER fill:#2e0d0d,stroke:#f85149,color:#ff7b72
    style ALERTS fill:#2e0d0d,stroke:#f85149,color:#ff7b72
```

| # | Module | Description |
|:-:|--------|-------------|
| 26 | **Confidence Timeline** | Temporal confidence tracking with SMA/EMA, plateau detection, convergence analysis, dC/dt |
| 27 | **Entropy Trend** | H(t) time series, first derivative dH/dt, second derivative dÂ²H/dtÂ², spike/collapse detection |
| 28 | **Drift Kinematics** | Velocity dd/dt, acceleration dÂ²d/dtÂ², jerk dÂ³d/dtÂ³, inflection point detection, kinematic phase classification |
| 29 | **Stability Classifier** | 5-state epistemic state machine: stable â†’ converging â†’ volatile â†’ diverging â†’ critical |
| 30 | **Alert Engine** | Rule-based anomaly detection across 9 alert types (entropy spike, confidence collapse, drift acceleration, tension surge, etc.) |
| 31 | **Lifecycle Report** | 10-section narrative report with trajectory scoring (0â€“100%), grade scale (Aâ€“F), actionable recommendations |

---

## ðŸŸ© Phase VI â€” Source Intelligence & Network Forensics

> ðŸŸ£ **Source-level credibility tracking, influence network analysis, coordination detection, and deep provenance tracing**

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    subgraph REPUTATION["Source Reputation"]
        R1["ðŸ“Š EMA Credibility\nÎ± = 0.3"]
        R2["ðŸ“ˆ Reliability Index\n4-component"]
        R3["ðŸ·ï¸ Aâ€“F Grading"]
    end

    subgraph NETWORK["Influence Network"]
        N1["ðŸ”— Edge\nConstruction"]
        N2["ðŸ“Š Centrality\nAnalysis"]
        N3["ðŸŽ¯ Gateway\nDetection"]
    end

    subgraph COORD["Coordination Detection"]
        D1["â±ï¸ Temporal\nClustering"]
        D2["ðŸŽ­ Pattern\nClassification"]
        D3["ðŸ“Š Scoring\n0â€“1"]
    end

    subgraph PROV["Deep Provenance"]
        P1["ðŸ” Mutation\nChain Walk"]
        P2["ðŸ·ï¸ Origin\nClassification"]
        P3["ðŸ“‰ Confidence\nDecay 0.85Ã—"]
    end

    subgraph REPORT["Forensics Report"]
        F1["ðŸ“‹ Single Source\n5 sections"]
        F2["ðŸŒ Ecosystem\n7 sections"]
        F3["ðŸ’Š Health\nAssessment"]
    end

    REPUTATION --> REPORT
    NETWORK --> REPORT
    COORD --> REPORT
    PROV --> REPORT

    style REPUTATION fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style NETWORK fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style COORD fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style PROV fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style REPORT fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
```

| # | Module | Description |
|:-:|--------|-------------|
| 32 | **Source Reputation** | EMA credibility tracking, Laplace-smoothed reliability, 4-component reliability index, Aâ€“F grading, trend direction |
| 33 | **Influence Network** | Source-to-source amplification edges, NetworkX centrality analysis, gateway/bottleneck detection, PageRank |
| 34 | **Coordination Detector** | Temporal burst/cascade/simultaneous pattern detection, sliding window clustering, coordination scoring |
| 35 | **Deep Provenance** | Mutation chain + source chain traversal, origin classification (original/derived/mutated/amplified/orphan), confidence decay |
| 36 | **Source Forensics Report** | 7-section ecosystem reports, single-source intelligence reports, ecosystem health assessment, quick summaries |

---

## ï¿½ Phase VII â€” Scientific Optimization & Blockchain Anchoring

> Advanced mathematical analysis, formal proof generation, Rust smart contracts, and deterministic on-chain anchoring.

```mermaid
%%{init: {'theme': 'dark'}}%%
graph LR
    subgraph MATH["âšª Mathematical Expansion"]
        MFD[Missing Factor<br/>Detector]
        SO[Solution<br/>Optimizer]
        SA[Stability<br/>Analyzer]
        CRM[Canonical<br/>Reference Map]
        FPE[Formal Proof<br/>Exporter]
    end

    subgraph OPT["âšª Optimization Metrics"]
        SI[Solvability<br/>Index]
        MES[Model Efficiency<br/>Score]
        CR[Compression<br/>Ratio]
    end

    subgraph PERF["âšª Performance"]
        AE[Async<br/>Executor]
        CM[Cache<br/>Manager]
        BS[Benchmark<br/>Suite]
    end

    subgraph CHAIN["âšª Blockchain"]
        RAB[Rust Anchor<br/>Bridge]
        RC[Rust Smart<br/>Contracts]
        REG[Scientific<br/>Registry]
    end

    MATH --> OPT
    OPT --> CHAIN
    PERF --> MATH
    CHAIN --> DB[(SQLite + Chain)]

    style MATH fill:#1a1a1a,stroke:#8b949e,color:#c9d1d9
    style OPT fill:#1a1a1a,stroke:#8b949e,color:#c9d1d9
    style PERF fill:#1a1a1a,stroke:#8b949e,color:#c9d1d9
    style CHAIN fill:#1a1a1a,stroke:#8b949e,color:#c9d1d9
```

| # | Module | Description |
|:-:|--------|-------------|
| 37 | **Missing Factor Detector** | Detects omitted physical constants (G, c, â„, k_B), dimensional inconsistencies, implicit unit assumptions, canonical deviations |
| 38 | **Solution Optimizer** | 8-strategy simplification (expand, factor, cancel, trigsimpâ€¦), compression ratio, overparameterization detection |
| 39 | **Stability Analyzer** | Jacobian computation, eigenvalue extraction, Lyapunov exponents, stability classification (7 classes) |
| 40 | **Canonical Reference Map** | 15 canonical equations (Newton â†’ Boltzmann), structural/algebraic comparison, closest-match finder |
| 41 | **Formal Proof Exporter** | Step-by-step proof trees, SMT-LIB 2.0 export (QF_NRA logic), axiom tracking, DB persistence |
| 42 | **Scientific Registry** | 12 default contributors (Newton â†’ Coulomb), domain filtering, equation/claim linking, SHA-256 hashing |
| 43 | **Solvability Index** | Formula: SI = C/(V+1) Ã— (1-S) Ã— D, stability class mapping, tractability interpretation |
| 44 | **Model Efficiency Score** | Operation count, AST depth, parameter count, normalized cost, efficiency scoring |
| 45 | **Compression Ratio** | Multi-strategy comparison, best strategy selection, equivalence verification |
| 46 | **Async Executor** | ThreadPoolExecutor batch processing, deterministic result ordering, error isolation |
| 47 | **Cache Manager** | SHA-256 keyed LRU cache, TTL expiry, deterministic invalidation, hit/miss statistics |
| 48 | **Benchmark Suite** | Context-manager timing, psutil memory/CPU tracking, JSON log export, DB persistence |
| 49 | **Rust Anchor Bridge** | Payloads for merkle_root/claim_score/equation_proof, dry-run mode, receipt verification |
| 50 | **Rust Smart Contracts** | CosmWasm-compatible contracts: anchor_registry, merkle_anchor, claim_score_anchor, equation_proof_anchor |

---

## ðŸŸ§ CLI Command Reference

> **87 commands** across 7 phases. All invoked via `python main.py`.

<details>
<summary><strong>ðŸŸ¢ Phase I â€” Research & Collection (21 commands)</strong></summary>

```bash
python main.py --collect              # Scrape social media / web
python main.py --academic             # Search academic databases
python main.py --government           # Search government records
python main.py --analyze-pdf FILE     # Analyze a specific PDF
python main.py --physics              # Run physics computations
python main.py --waves                # Run wave science computations
python main.py --nlp                  # Run narrative NLP analysis
python main.py --graph                # Build propagation graph
python main.py --report               # Generate JSON reports
python main.py --static-report        # Generate HTML report
python main.py --dashboard            # Launch interactive dashboard

# IPFS commands (requires local Kubo node):
python main.py --ipfs-status          # Show IPFS node status
python main.py --ipfs-archive         # Archive all evidence to IPFS
python main.py --ipfs-pin FILE        # Pin a specific file
python main.py --ipfs-verify          # Verify proof chain integrity
python main.py --gateway-health       # Check multi-gateway health

# Extended research:
python main.py --taxonomy             # Load taxonomy knowledge base
python main.py --taxonomy-search TERM # Search taxonomy entries
python main.py --taxonomy-export      # Export taxonomy to JSON
python main.py --arxiv TERM           # Search arXiv
python main.py --extended-search      # Run all extended terms
```

</details>

<details>
<summary><strong>ðŸ”µ Phase II â€” Cryptographic Integrity (12 commands)</strong></summary>

```bash
python main.py --key-generate         # Generate Ed25519 signing keypair
python main.py --sign-cid CID        # Sign a CID with default key
python main.py --verify-cid CID      # Verify a CID signature
python main.py --snapshot             # Create Merkle snapshot of database
python main.py --verify-snapshot      # Verify latest Merkle snapshot
python main.py --ipns-publish CID    # Publish CID to IPNS
python main.py --ipns-resolve         # Resolve current IPNS pointer
python main.py --generate-audit       # Generate comprehensive audit report
python main.py --foia-search QUERY   # Search all FOIA sources
python main.py --tesla                # Run Tesla investigation
python main.py --load-scientists      # Load scientist cases database
python main.py --search-scientists Q  # Search scientist cases
```

</details>

<details>
<summary><strong>ðŸŸ¡ Phase III â€” Mathematical Framework (11 commands)</strong></summary>

```bash
python main.py --parse-equation 'E = m*c**2'   # Parse plaintext equation
python main.py --parse-latex '\frac{1}{2}mv^2'  # Parse LaTeX equation
python main.py --dim-check newton_gravity       # Dimensional analysis
python main.py --simplify-eq 'x**2 + 2*x + 1'  # Simplify expression
python main.py --math-audit                     # Full math forensics audit

python main.py --add-claim "claim text"         # Add claim to graph
python main.py --add-source "source title"      # Add source node
python main.py --link-claim 'cid,sid,supports'  # Link claim to source
python main.py --claim-stats                    # Show graph statistics
python main.py --provenance ID                  # Show claim provenance chain
python main.py --contradictions                 # List all contradictions
```

</details>

<details>
<summary><strong>ðŸŸ  Phase IV â€” Quantitative Scoring (8 commands)</strong></summary>

```bash
python main.py --score-claim ID       # Bayesian confidence score
python main.py --score-all            # Score all claims, rank results
python main.py --mutation-entropy ID  # Mutation entropy analysis
python main.py --citation-density ID  # Citation density analysis
python main.py --tension-map          # Show contradiction tension map
python main.py --propagation ID       # Track propagation velocity
python main.py --claim-report [ID]    # Full epistemic scoring report
python main.py --quick-score ID       # One-line epistemic summary
```

</details>

<details>
<summary><strong>ðŸ”´ Phase V â€” Temporal Dynamics (11 commands)</strong></summary>

```bash
python main.py --conf-snapshot [ID]        # Snapshot confidence (0=all)
python main.py --conf-trend ID             # Confidence trend analysis
python main.py --entropy-snapshot [ID]     # Snapshot entropy (0=all)
python main.py --entropy-trend ID          # Entropy trend analysis
python main.py --drift-kinematics ID       # Drift kinematics analysis
python main.py --classify-claim ID         # Classify stability state
python main.py --classify-all              # Classify all claims
python main.py --alert-scan [ID]           # Scan for anomaly alerts (0=all)
python main.py --alert-list                # List pending alerts
python main.py --lifecycle [ID]            # Lifecycle report (0=system)
python main.py --quick-lifecycle ID        # One-line lifecycle summary
```

</details>

<details>
<summary><strong>ðŸŸ£ Phase VI â€” Source Intelligence (11 commands)</strong></summary>

```bash
python main.py --source-snapshot [ID]      # Snapshot source reputation (0=all)
python main.py --source-profile ID         # Full reputation profile
python main.py --source-rank               # Rank all sources by reliability
python main.py --influence-build           # Build source influence edges
python main.py --influence-network         # Analyze the influence network
python main.py --coord-scan [WINDOW]       # Scan for coordination (default: 24h)
python main.py --coord-summary             # Coordination detection summary
python main.py --provenance-trace [ID]     # Deep provenance trace (0=all)
python main.py --provenance-summary        # Deep provenance summary
python main.py --source-report [ID]        # Source forensics report (0=ecosystem)
python main.py --quick-source ID           # One-line source intelligence summary
```

</details>

<details>
<summary><strong>âšª Phase VII â€” Scientific Optimization & Blockchain (10 commands)</strong></summary>

```bash
python main.py --detect-missing 'm*c**2'        # Detect missing factors in equation
python main.py --optimize-equation 'x**2+2*x+1' # Optimize / simplify equation
python main.py --stability-analysis '-x,-2*y'   # Stability analysis (comma-sep system)
python main.py --formal-proof 'm*c**2'           # Generate formal proof tree + SMT-LIB
python main.py --solvability 'm*c**2'            # Compute solvability index
python main.py --efficiency-score 'G*m1*m2/r**2' # Compute model efficiency score
python main.py --scientist-link 'Newton,42'      # Link scientist to claim ID
python main.py --anchor-root HASH                # Anchor Merkle root to blockchain
python main.py --anchor-equation 'm*c**2'        # Anchor equation proof to blockchain
python main.py --benchmark                       # Run performance benchmarks
```

</details>

---

## ðŸŸª Database Schema

> **39 tables** in SQLite WAL mode at `data/project_anchor.db`

```mermaid
%%{init: {'theme': 'dark'}}%%
erDiagram
    CLAIM_NODES ||--o{ EVIDENCE_LINKS : "linked via"
    SOURCE_NODES ||--o{ EVIDENCE_LINKS : "provides"
    CLAIM_NODES ||--o{ CLAIM_SCORES : "scored by"
    CLAIM_NODES ||--o{ MUTATION_METRICS : "tracked by"
    CLAIM_NODES ||--o{ CONFIDENCE_TIMELINE : "snapshot"
    CLAIM_NODES ||--o{ ENTROPY_TIMELINE : "entropy"
    CLAIM_NODES ||--o{ STABILITY_CLASSIFICATIONS : "classified"
    CLAIM_NODES ||--o{ PROVENANCE_TRACES : "traced"
    SOURCE_NODES ||--o{ SOURCE_REPUTATION : "reputation"
    SOURCE_NODES ||--o{ INFLUENCE_EDGES : "influences"
    CLAIM_NODES ||--o{ COORDINATION_EVENTS : "coordinated"
```

<details>
<summary><strong>ðŸŸ¢ Phase I â€” Collection & Archive (9 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `social_posts` | Scraped social media posts |
| `documents` | PDF analysis results |
| `academic_records` | Publication search results |
| `government_records` | Public record query results |
| `propagation_edges` | Information spread graph |
| `physics_comparisons` | Computed physics values |
| `narrative_patterns` | NLP analysis results |
| `ipfs_evidence` | IPFS-pinned evidence CIDs & proof chain |
| `taxonomy_entries` | Taxonomy knowledge base entries |

</details>

<details>
<summary><strong>ðŸ”µ Phase II â€” Integrity & Research (7 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `crypto_keys` | Ed25519 signing keypair metadata |
| `merkle_snapshots` | Merkle tree snapshot records |
| `foia_documents` | FOIA document records |
| `investigation_cases` | Investigation case records |
| `case_claims` | Claims linked to investigation cases |
| `scientist_cases` | Historical scientist case records |
| `audit_logs` | Audit trail entries |

</details>

<details>
<summary><strong>ðŸŸ¡ Phase III â€” Mathematical & Graph (6 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `equation_proofs` | Parsed equation metadata & hashes |
| `derivation_steps` | Step-by-step derivation chain records |
| `claim_nodes` | Typed claim nodes in evidence graph |
| `source_nodes` | Source nodes (documents, academic, social) |
| `evidence_links` | Weighted edges between nodes |
| `entity_nodes` | Person/organization entity nodes |

</details>

<details>
<summary><strong>ðŸŸ  Phase IV â€” Scoring (3 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `claim_scores` | Bayesian confidence score breakdowns |
| `mutation_metrics` | Shannon entropy & drift velocity metrics |
| `propagation_events` | Propagation event log (platform, reach, timestamp) |

</details>

<details>
<summary><strong>ðŸ”´ Phase V â€” Temporal Dynamics (4 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `confidence_timeline` | Confidence score snapshots over time |
| `entropy_timeline` | Shannon entropy snapshots over time |
| `stability_classifications` | Epistemic state classifications |
| `epistemic_alerts` | Anomaly alerts with severity levels |

</details>

<details>
<summary><strong>ðŸŸ£ Phase VI â€” Source Intelligence (4 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `source_reputation` | Source reliability snapshots (EMA, accuracy, trend) |
| `influence_edges` | Source-to-source amplification edges (shared claims, directionality) |
| `coordination_events` | Detected temporal coordination clusters (scores, patterns) |
| `provenance_traces` | Deep provenance traces (origin type, chain depth, confidence) |

</details>

<details>
<summary><strong>âšª Phase VII â€” Scientific Optimization (6 tables)</strong></summary>

| Table | Content |
|-------|---------|
| `scientific_registry` | Contributor records (domain, equations, citations, SHA-256) |
| `equation_stability` | Jacobian, eigenvalues, Lyapunov exponents, stability class |
| `equation_optimization` | Original/simplified expressions, compression ratio, missing factors |
| `formal_proofs` | Proof trees (JSON), SMT-LIB exports, axioms, validity flags |
| `blockchain_anchors` | Anchor payloads, transaction IDs, on-chain hashes, receipt status |
| `performance_metrics` | Operation timings, memory/CPU usage, benchmark metadata |

</details>

All operations are logged to timestamped files in `logs/`.

---

## ðŸŸ¥ Scoring & Algorithm Reference

### Bayesian Confidence Scoring (ðŸŸ  Phase IV)

> Six-component weighted composite:

```
C(claim) = wâ‚Â·Prior + wâ‚‚Â·Credibility + wâ‚ƒÂ·Citation + wâ‚„Â·Contradiction + wâ‚…Â·Verification + wâ‚†Â·MutationDecay
```

| Component | Description |
|-----------|-------------|
| **Prior** | Base probability by claim type (observation, hypothesis, rebuttal) |
| **Source Credibility** | Average credibility of linked sources |
| **Citation Support** | Cross-reference density and quality weighting |
| **Contradiction Penalty** | Log-scaled tension from opposing claims |
| **Verification Bonus** | Status-based modifier (confirmed â†’ retracted) |
| **Mutation Decay** | Confidence loss through claim text drift |

### Trajectory Scoring (ðŸ”´ Phase V)

> Weighted composite score (0â€“100%) with letter grade:

| Component | Weight | Signal |
|-----------|:------:|--------|
| Confidence stability | 30% | Low Ïƒ across timeline |
| Entropy stability | 25% | Low dH/dt |
| Drift stability | 20% | Low acceleration |
| Classification bonus | 15% | Stable/converging state |
| Alert penalty | 10% | Fewer anomaly flags |

> **Grade scale:** `A` (90+) Â· `B` (75+) Â· `C` (60+) Â· `D` (40+) Â· `F` (<40)

### Source Reputation Index (ðŸŸ£ Phase VI)

> Four-component weighted reliability index:

```
R(source) = 0.40Â·Accuracy + 0.30Â·EMA + 0.20Â·Consistency + 0.10Â·Volume
```

| Component | Weight | Formula |
|-----------|:------:|---------|
| Accuracy rate | 40% | `(support + 1) / (total + 2)` â€” Laplace smoothed |
| EMA credibility | 30% | Exponential moving average, Î± = 0.3 |
| Consistency | 20% | `1 âˆ’ 3Ïƒ` of reliability history |
| Volume bonus | 10% | `logâ‚‚(claim_count + 1) / 10`, capped at 1.0 |

> **Grade scale:** `A` (â‰¥0.90) Â· `B` (â‰¥0.75) Â· `C` (â‰¥0.60) Â· `D` (â‰¥0.40) Â· `F` (<0.40)

### Coordination Scoring (ðŸŸ£ Phase VI)

> Three-component coordination score:

```
S(cluster) = 0.35Â·CountFactor + 0.40Â·Tightness + 0.25Â·DensityFactor
```

| Component | Weight | Formula |
|-----------|:------:|---------|
| Count factor | 35% | `logâ‚‚(source_count) / logâ‚‚(max_expected)` |
| Tightness | 40% | `1 âˆ’ (time_spread / window_hours)` |
| Density factor | 25% | `sources_per_hour`, capped at 1.0 |

> **Pattern types:** `simultaneous` (spread < 1h) Â· `cascade` (spread < 30% window) Â· `burst` (default)

### Ecosystem Health (ðŸŸ£ Phase VI)

```
H(ecosystem) = 0.40Â·Reliability + 0.25Â·(1 âˆ’ OrphanRate) + 0.20Â·Connectivity + 0.15Â·(1 âˆ’ MaxCoordScore)
```

| Component | Weight | Description |
|-----------|:------:|-------------|
| Mean source reliability | 40% | Average reliability index across all sources |
| Low orphan rate | 25% | `1 âˆ’ (orphan claims / total claims)` |
| Network connectivity | 20% | `1 âˆ’ fragmentation ratio` |
| Low coordination suspicion | 15% | `1 âˆ’ highest coordination score` |

### Provenance Classification (ðŸŸ£ Phase VI)

| Origin Type | Criteria |
|-------------|----------|
| `original` | No mutation parent, has source links |
| `derived` | Mutation chain, Jaccard similarity â‰¥ 0.5 |
| `mutated` | Mutation chain, Jaccard similarity < 0.5 |
| `amplified` | Multiple sources, no mutation parent |
| `orphan` | No sources, no parent |

> **Confidence decay:** 0.85Ã— per chain hop. Max trace depth: 20.

### Stability State Machine (ðŸ”´ Phase V)

```mermaid
%%{init: {'theme': 'dark'}}%%
stateDiagram-v2
    [*] --> Stable
    Stable --> Converging : variance decreasing
    Stable --> Volatile : Ïƒ spike
    Converging --> Stable : plateau reached
    Converging --> Volatile : Ïƒ reversal
    Volatile --> Diverging : drift + entropy â†‘
    Volatile --> Converging : settling
    Diverging --> Critical : 3+ anomaly flags
    Diverging --> Volatile : drift slows
    Critical --> Volatile : flags resolved
    Critical --> Diverging : partial recovery
```

| State | Description |
|-------|-------------|
| ðŸŸ¢ **Stable** | Low variance, consistent metrics across all temporal signals |
| ðŸ”µ **Converging** | Decreasing variance, narrowing oscillation, approaching plateau |
| ðŸŸ¡ **Volatile** | High variance in confidence or entropy, frequent direction changes |
| ðŸŸ  **Diverging** | Accelerating drift combined with increasing entropy |
| ðŸ”´ **Critical** | Three or more simultaneous anomaly flags from different subsystems |

### Alert Types (ðŸ”´ Phase V)

> Nine categories across three severity levels:

| Alert | Severity | Trigger |
|-------|:--------:|---------|
| `entropy_spike` | âš ï¸ Warning | H(t) exceeds 2Ïƒ above mean |
| `entropy_collapse` | ðŸš¨ Critical | H(t) drops below 2Ïƒ below mean |
| `confidence_collapse` | ðŸš¨ Critical | C(t) drops below 2Ïƒ below mean |
| `confidence_surge` | âš ï¸ Warning | C(t) exceeds 2Ïƒ above mean |
| `drift_acceleration` | âš ï¸ Warning | dÂ²d/dtÂ² exceeds threshold |
| `drift_inflection` | â„¹ï¸ Info | Sign change in acceleration |
| `tension_surge` | âš ï¸ Warning | Contradiction tension spike |
| `stability_transition` | â„¹ï¸ Info | State machine transition |
| `critical_state` | ðŸš¨ Critical | Claim enters critical state |

---

## ðŸŸ¥ Flow Diagrams

### Complete Data Pipeline

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    START(["ðŸš€ python main.py --all"])

    subgraph COLLECT["ðŸŸ¢ PHASE I: COLLECT"]
        C1["Scrape Reddit\nWayback\nWeb Search"]
        C2["Query Gov DBs\nAcademic DBs"]
        C3["Analyze PDFs"]
        C4["Run Physics\nEngine"]
        C5["NLP Analysis"]
        C6["Pin to IPFS"]
    end

    subgraph SECURE["ðŸ”µ PHASE II: SECURE"]
        S1["Sign with\nEd25519"]
        S2["Merkle\nSnapshot"]
        S3["FOIA\nForensics"]
        S4["Generate\nAudit"]
    end

    subgraph MATH["ðŸŸ¡ PHASE III: MODEL"]
        M1["Parse\nEquations"]
        M2["Dimensional\nAnalysis"]
        M3["Build Claim\nGraph"]
    end

    subgraph SCORE["ðŸŸ  PHASE IV: SCORE"]
        SC1["Bayesian\nConfidence"]
        SC2["Mutation\nEntropy"]
        SC3["Citation\nDensity"]
        SC4["Contradiction\nMapping"]
    end

    subgraph TEMPORAL["ðŸ”´ PHASE V: TRACK"]
        T1["Confidence\nTimeline"]
        T2["Entropy\nTrend"]
        T3["Drift\nKinematics"]
        T4["Classify\nStability"]
        T5["Alert\nScan"]
    end

    subgraph INTEL["ðŸŸ£ PHASE VI: INTELLIGENCE"]
        I1["Source\nReputation"]
        I2["Influence\nNetwork"]
        I3["Coordination\nDetection"]
        I4["Deep\nProvenance"]
        I5["Forensics\nReport"]
    end

    FINISH(["ðŸ“Š Reports & Dashboard"])

    START --> COLLECT
    COLLECT --> SECURE
    SECURE --> MATH
    MATH --> SCORE
    SCORE --> TEMPORAL
    TEMPORAL --> INTEL
    INTEL --> FINISH

    style START fill:#0d1117,stroke:#58a6ff,color:#58a6ff
    style COLLECT fill:#0d2818,stroke:#2ea043,color:#7ee787
    style SECURE fill:#0d1b2e,stroke:#58a6ff,color:#79c0ff
    style MATH fill:#2e2a0d,stroke:#d29922,color:#e3b341
    style SCORE fill:#2e1a0d,stroke:#f0883e,color:#ffa657
    style TEMPORAL fill:#2e0d0d,stroke:#f85149,color:#ff7b72
    style INTEL fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style FINISH fill:#0d1117,stroke:#58a6ff,color:#58a6ff
```

### Scoring Cascade Flow

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph RAW["Raw Signals"]
        R1["Source Links"]
        R2["Claim Text"]
        R3["Timestamps"]
        R4["Contradictions"]
    end

    subgraph P4["ðŸŸ  Phase IV Scores"]
        S1["Bayesian\nConfidence"]
        S2["Shannon\nEntropy"]
        S3["Citation\nDensity"]
        S4["Tension\nMap"]
    end

    subgraph P5["ðŸ”´ Phase V Dynamics"]
        D1["dC/dt"]
        D2["dH/dt Â· dÂ²H/dtÂ²"]
        D3["Velocity Â· Accel\nJerk"]
        D4["State\nClassification"]
    end

    subgraph P6["ðŸŸ£ Phase VI Intel"]
        I1["Source\nReliability"]
        I2["Network\nCentrality"]
        I3["Coordination\nScore"]
        I4["Provenance\nChain"]
    end

    VERDICT["ðŸ“Š Epistemic\nVerdict"]

    R1 & R2 & R3 & R4 --> P4
    P4 --> P5
    P5 --> P6
    P6 --> VERDICT

    style RAW fill:#161b22,stroke:#8b949e,color:#c9d1d9
    style P4 fill:#2e1a0d,stroke:#f0883e,color:#ffa657
    style P5 fill:#2e0d0d,stroke:#f85149,color:#ff7b72
    style P6 fill:#1f0d2e,stroke:#a371f7,color:#d2a8ff
    style VERDICT fill:#0d1117,stroke:#58a6ff,color:#58a6ff
```

---

## â¬œ Testing

> **390 tests** Â· **10 test suites** Â· All passing

```mermaid
%%{init: {'theme': 'dark'}}%%
pie title Test Distribution by Phase (390 total)
    "ðŸŸ¢ Phase I : 9" : 9
    "ðŸ”µ Phase II : 24" : 24
    "ðŸŸ¡ Phase III : 34" : 34
    "ðŸŸ  Phase IV : 42" : 42
    "ðŸ”´ Phase V : 75" : 75
    "ðŸŸ£ Phase VI : 100" : 100
    "âšª Phase VII : 106" : 106
```

```bash
# Run full suite
python -m pytest tests/ -v                             # 390 tests

# Run by phase
python -m pytest tests/test_physics.py -v              # ðŸŸ¢   9 tests â€” Physics engine
python -m pytest tests/test_phase2.py -v               # ðŸ”µ  24 tests â€” Crypto & integrity
python -m pytest tests/test_phase3.py -v               # ðŸŸ¡  34 tests â€” Math & claim graph
python -m pytest tests/test_phase4.py -v               # ðŸŸ   42 tests â€” Scoring engine
python -m pytest tests/test_phase5.py -v               # ðŸ”´  75 tests â€” Temporal dynamics
python -m pytest tests/test_phase6.py -v               # ðŸŸ£ 100 tests â€” Source intelligence
python -m pytest tests/test_phase7_math.py -v          # âšª  40 tests â€” Math expansion
python -m pytest tests/test_phase7_anchor.py -v        # âšª  14 tests â€” Blockchain anchoring
python -m pytest tests/test_phase7_registry.py -v      # âšª  18 tests â€” Scientific registry
python -m pytest tests/test_phase7_performance.py -v   # âšª  34 tests â€” Performance & optimization
```

All tests use `:memory:` SQLite via `PROJECT_ANCHOR_DB` environment variable.

---

## â¬œ IPFS Integration

The system integrates with a local **IPFS Kubo node** for immutable, content-addressed evidence storage:

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph IPFS_FLOW["IPFS Evidence Pipeline"]
        A["ðŸ“„ Evidence\nDocument"] --> B["ðŸ“Œ Pin to\nIPFS"]
        B --> C["ðŸ”— Get CID"]
        C --> D["â›“ï¸ Link to\nProof Chain"]
        D --> E["âœï¸ Ed25519\nSign CID"]
        E --> F["ðŸ“¢ Publish\nto IPNS"]
    end

    style IPFS_FLOW fill:#0d1117,stroke:#65c2cb,color:#65c2cb
```

| Feature | Description |
|---------|-------------|
| **Proof Chain** | Each evidence item pinned to IPFS and linked into a DAG chain with tamper-evident CID references |
| **Content Addressing** | Every item gets a CID â€” a cryptographic hash. Any byte change produces a new CID |
| **SHA-256 Verification** | Independent SHA-256 hashes stored alongside CIDs for double verification |
| **IPNS Publishing** | Chain head published to IPNS for a stable, updatable reference |
| **Multi-Gateway** | Health checking and pinning across multiple IPFS gateways |

### Requirements

| Component | Endpoint |
|-----------|----------|
| IPFS Kubo (desktop or daemon) | Running locally |
| RPC API | `http://127.0.0.1:5001` |
| Gateway | `http://127.0.0.1:8081` |

### Workflow

```bash
python main.py --ipfs-status          # 1. Check node is online
python main.py --all                  # 2. Run research pipeline
python main.py --ipfs-archive         # 3. Archive everything to IPFS
python main.py --ipfs-verify          # 4. Verify proof chain integrity
python main.py --ipfs-pin doc.pdf     # 5. Pin a specific document
```

---

## â¬œ Operational Scope & Reproducibility

### Scope

This system is limited to:
- âœ… Publicly accessible data
- âœ… Public records & open-source intelligence
- âœ… Public academic databases

It does **not**:
- âŒ Access classified systems
- âŒ Bypass encryption
- âŒ Access restricted government networks

### Reproducibility Guarantees

| Guarantee | Mechanism |
|-----------|-----------|
| Source citation | All sources cited with URLs and timestamps |
| Audit trail | All operations logged with full audit trail |
| Portability | Self-contained SQLite database |
| Documentation | Physics equations and constants documented inline |
| Tamper evidence | Cryptographic signatures on all evidence |
| Integrity verification | Merkle snapshots verify database state |
| No API keys required | Basic operation works without external keys |

---

## â¬œ Quick Start

```bash
# Clone repository
git clone https://github.com/FTHTrading/Gravity-.git
cd Gravity-

# Install dependencies
pip install -r requirements.txt

# Initialize database
python main.py --init-db

# Run complete pipeline
python main.py --all

# Check system status
python main.py --claim-stats
```

---

## â¬œ Dependencies

**Python 3.11+** with:

| Package | Purpose |
|---------|---------|
| `requests` | HTTP client for API calls |
| `PyMuPDF` | PDF parsing and metadata extraction |
| `pdfminer.six` | PDF text extraction |
| `nltk` | Natural language processing |
| `scikit-learn` | TF-IDF vectorization, cosine similarity |
| `networkx` | Graph analysis, centrality, PageRank |
| `matplotlib` | Static chart generation |
| `plotly` | Interactive visualizations |
| `dash` | Web dashboard framework |
| `python-dateutil` | Date parsing and manipulation |
| `cryptography` | Ed25519 signatures (v46.0+) |
| `sympy` | Symbolic mathematics CAS (v1.14+) |
| `pytest` | Test framework |

---

<p align="center">
  <sub>Built with forensic precision. Every claim tracked. Every source measured. Every change recorded.</sub>
</p>
